{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers","metadata":{"id":"VEUfZGNsIzlF","outputId":"8268ca45-df69-49ed-f658-36cc76c7dddb","execution":{"iopub.status.busy":"2023-10-05T09:16:22.805587Z","iopub.execute_input":"2023-10-05T09:16:22.805908Z","iopub.status.idle":"2023-10-05T09:16:31.940048Z","shell.execute_reply.started":"2023-10-05T09:16:22.805884Z","shell.execute_reply":"2023-10-05T09:16:31.938800Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.33.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.12.2)\nRequirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.16.4)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.23.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.6.3)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.13.3)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.3.3)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.1)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.9.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.6.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.0.9)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2023.7.22)\n","output_type":"stream"}]},{"cell_type":"code","source":"import re\nimport string\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport tensorflow as tf\nimport transformers\nfrom transformers import BertTokenizer\nfrom transformers import TFAutoModel","metadata":{"id":"olfs86F6IazQ","execution":{"iopub.status.busy":"2023-10-05T09:16:31.942367Z","iopub.execute_input":"2023-10-05T09:16:31.942742Z","iopub.status.idle":"2023-10-05T09:16:31.950693Z","shell.execute_reply.started":"2023-10-05T09:16:31.942705Z","shell.execute_reply":"2023-10-05T09:16:31.949883Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/testtrainsample/train.csv')\ntest = pd.read_csv('/kaggle/input/testtrainsample/test.csv')","metadata":{"id":"bKv9LnETI9yD","execution":{"iopub.status.busy":"2023-10-05T09:16:31.953155Z","iopub.execute_input":"2023-10-05T09:16:31.953573Z","iopub.status.idle":"2023-10-05T09:16:32.034148Z","shell.execute_reply.started":"2023-10-05T09:16:31.953519Z","shell.execute_reply":"2023-10-05T09:16:32.033212Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"id":"h8Ww0s--Jdib","outputId":"244d7c20-d1c1-4387-fd8e-f557e0d0e889","execution":{"iopub.status.busy":"2023-10-05T09:16:32.036566Z","iopub.execute_input":"2023-10-05T09:16:32.036883Z","iopub.status.idle":"2023-10-05T09:16:32.059443Z","shell.execute_reply.started":"2023-10-05T09:16:32.036852Z","shell.execute_reply":"2023-10-05T09:16:32.058652Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"   id keyword location                                               text  \\\n0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n\n   target  \n0       1  \n1       1  \n2       1  \n3       1  \n4       1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>keyword</th>\n      <th>location</th>\n      <th>text</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Our Deeds are the Reason of this #earthquake M...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Forest fire near La Ronge Sask. Canada</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>All residents asked to 'shelter in place' are ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>6</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>13,000 people receive #wildfires evacuation or...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train[\"length\"] = train[\"text\"].apply(lambda x : len(x))\ntest[\"length\"] = test[\"text\"].apply(lambda x : len(x))","metadata":{"id":"QxUxxbN4Jg9a","execution":{"iopub.status.busy":"2023-10-05T09:16:32.060599Z","iopub.execute_input":"2023-10-05T09:16:32.062455Z","iopub.status.idle":"2023-10-05T09:16:32.075217Z","shell.execute_reply.started":"2023-10-05T09:16:32.062424Z","shell.execute_reply":"2023-10-05T09:16:32.074017Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"train[\"length\"].describe()","metadata":{"id":"qf8NXNndJjZv","outputId":"5aa1b605-ecba-4976-ea38-e4ac490be2c1","execution":{"iopub.status.busy":"2023-10-05T09:16:32.076979Z","iopub.execute_input":"2023-10-05T09:16:32.077364Z","iopub.status.idle":"2023-10-05T09:16:32.094291Z","shell.execute_reply.started":"2023-10-05T09:16:32.077324Z","shell.execute_reply":"2023-10-05T09:16:32.093052Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"count    7613.000000\nmean      101.037436\nstd        33.781325\nmin         7.000000\n25%        78.000000\n50%       107.000000\n75%       133.000000\nmax       157.000000\nName: length, dtype: float64"},"metadata":{}}]},{"cell_type":"code","source":"train['text'] = train['text'].apply(lambda x: \" \".join([word.lower() for word in str(x).split()]))\ntest['text'] = test['text'].apply(lambda x: \" \".join([word.lower() for word in str(x).split()]))","metadata":{"id":"Sp_9bLb-Jpyp","execution":{"iopub.status.busy":"2023-10-05T09:16:32.095788Z","iopub.execute_input":"2023-10-05T09:16:32.096421Z","iopub.status.idle":"2023-10-05T09:16:32.136543Z","shell.execute_reply.started":"2023-10-05T09:16:32.096390Z","shell.execute_reply":"2023-10-05T09:16:32.135706Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"import re\ndef remove_html(text):\n    html=re.compile(r'<.*?>')\n    return html.sub(r'',text)\n\ndef remove_emoji(text):\n    emoji_pattern = re.compile(\"[\"\n                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n                               u\"\\U00002702-\\U000027B0\"\n                               u\"\\U000024C2-\\U0001F251\"\n                               \"]+\", flags=re.UNICODE)\n    return emoji_pattern.sub(r'', text)\n\ndef decontraction(text):\n    text = re.sub(r\"won\\'t\", \" will not\", text)\n    text = re.sub(r\"won\\'t've\", \" will not have\", text)\n    text = re.sub(r\"can\\'t\", \" can not\", text)\n    text = re.sub(r\"don\\'t\", \" do not\", text)\n\n    text = re.sub(r\"can\\'t've\", \" can not have\", text)\n    text = re.sub(r\"ma\\'am\", \" madam\", text)\n    text = re.sub(r\"let\\'s\", \" let us\", text)\n    text = re.sub(r\"ain\\'t\", \" am not\", text)\n    text = re.sub(r\"shan\\'t\", \" shall not\", text)\n    text = re.sub(r\"sha\\n't\", \" shall not\", text)\n    text = re.sub(r\"o\\'clock\", \" of the clock\", text)\n    text = re.sub(r\"y\\'all\", \" you all\", text)\n\n    text = re.sub(r\"n\\'t\", \" not\", text)\n    text = re.sub(r\"n\\'t've\", \" not have\", text)\n    text = re.sub(r\"\\'re\", \" are\", text)\n    text = re.sub(r\"\\'s\", \" is\", text)\n    text = re.sub(r\"\\'d\", \" would\", text)\n    text = re.sub(r\"\\'d've\", \" would have\", text)\n    text = re.sub(r\"\\'ll\", \" will\", text)\n    text = re.sub(r\"\\'ll've\", \" will have\", text)\n    text = re.sub(r\"\\'t\", \" not\", text)\n    text = re.sub(r\"\\'ve\", \" have\", text)\n    text = re.sub(r\"\\'m\", \" am\", text)\n    text = re.sub(r\"\\'re\", \" are\", text)\n    return text\n\ndef clean(tweet):\n\n    tweet = re.sub(r\"https?:\\/\\/t.co\\/[A-Za-z0-9]+\", \"\", tweet)\n\n    Special = '@#!?+&*[]-%:/()$=><|{}^'\n    for s in Special:\n        tweet = tweet.replace(s, \"\")\n\n    return tweet\n\ntrain['text'] = train['text'].apply(lambda s : clean(s))\ntest['text'] = test['text'].apply(lambda s : clean(s))\ntrain['text'] = train['text'].apply(lambda s : remove_html(s))\ntest['text'] = test['text'].apply(lambda s : remove_html(s))\ntrain['text'] = train['text'].apply(lambda s : remove_emoji(s))\ntest['text'] = test['text'].apply(lambda s : remove_emoji(s))\ntrain['text'] = train['text'].apply(lambda s : decontraction(s))\ntest['text'] = test['text'].apply(lambda s : decontraction(s))","metadata":{"id":"ypD8tFlZJsCI","execution":{"iopub.status.busy":"2023-10-05T09:16:32.138153Z","iopub.execute_input":"2023-10-05T09:16:32.138677Z","iopub.status.idle":"2023-10-05T09:16:32.436145Z","shell.execute_reply.started":"2023-10-05T09:16:32.138647Z","shell.execute_reply":"2023-10-05T09:16:32.435173Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"id":"tK7ASXtTJwnf","outputId":"71e56afa-5406-4a7c-d5f8-d01f14e24a56","execution":{"iopub.status.busy":"2023-10-05T09:16:32.438280Z","iopub.execute_input":"2023-10-05T09:16:32.438839Z","iopub.status.idle":"2023-10-05T09:16:32.452115Z","shell.execute_reply.started":"2023-10-05T09:16:32.438805Z","shell.execute_reply":"2023-10-05T09:16:32.451020Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"   id keyword location                                               text  \\\n0   1     NaN      NaN  our deeds are the reason of this earthquake ma...   \n1   4     NaN      NaN             forest fire near la ronge sask. canada   \n2   5     NaN      NaN  all residents asked to  ishelter in place' are...   \n3   6     NaN      NaN  13,000 people receive wildfires evacuation ord...   \n4   7     NaN      NaN  just got sent this photo from ruby alaska as s...   \n\n   target  length  \n0       1      69  \n1       1      38  \n2       1     133  \n3       1      65  \n4       1      88  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>keyword</th>\n      <th>location</th>\n      <th>text</th>\n      <th>target</th>\n      <th>length</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>our deeds are the reason of this earthquake ma...</td>\n      <td>1</td>\n      <td>69</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>forest fire near la ronge sask. canada</td>\n      <td>1</td>\n      <td>38</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>all residents asked to  ishelter in place' are...</td>\n      <td>1</td>\n      <td>133</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>6</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>13,000 people receive wildfires evacuation ord...</td>\n      <td>1</td>\n      <td>65</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>just got sent this photo from ruby alaska as s...</td>\n      <td>1</td>\n      <td>88</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"import tensorflow as tf\nseq_len = 256\nbatch_size = 40\nnum_samples = len(train)\nmodel_name = 'cardiffnlp/twitter-roberta-base-sentiment'\n\ntokenizer = transformers.AutoTokenizer.from_pretrained(model_name)\n\ntrain_tokens = tokenizer(\n    train['text'].tolist(),\n    max_length=seq_len,\n    truncation=True,\n    padding='max_length',\n    add_special_tokens=True,\n    return_tensors='np'\n)\n#one hot encoding\ny_train = train['target'].values\nlabels = np.zeros((num_samples, y_train.max() + 1))\nlabels[np.arange(num_samples), y_train] = 1\n\ndataset = tf.data.Dataset.from_tensor_slices(\n    (\n        train_tokens['input_ids'],\n        train_tokens['attention_mask'],\n        labels\n    )\n)\n\ndef map_func(input_ids, masks, labels):\n    return {\n        'input_ids': input_ids,\n        'attention_mask': masks\n    }, labels\n\ndataset = dataset.map(map_func)\ndataset = dataset.shuffle(10000).batch(batch_size=batch_size, drop_remainder=True)\n\nsplit = 0.7\nsize = int((train_tokens['input_ids'].shape[0] // batch_size) * split)\n\ntrain_ds = dataset.take(size)\nval_ds = dataset.skip(size)","metadata":{"id":"3_8EnZubJyv3","outputId":"4f840e8f-8f7f-4f11-b468-28c5994cbf09","execution":{"iopub.status.busy":"2023-10-05T09:16:32.456063Z","iopub.execute_input":"2023-10-05T09:16:32.456810Z","iopub.status.idle":"2023-10-05T09:16:35.416950Z","shell.execute_reply.started":"2023-10-05T09:16:32.456768Z","shell.execute_reply":"2023-10-05T09:16:35.416005Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/747 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"49164da1f40a4a0286e8a2ad0eab05b9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)olve/main/vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d0ae6e5e3c7e48d5af0e74000277b4d0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e88517ba917a412980c592f76cf246fb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)cial_tokens_map.json:   0%|          | 0.00/150 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7302458dd94f43ccba8833d95b5e258e"}},"metadata":{}}]},{"cell_type":"code","source":"model = TFAutoModel.from_pretrained(model_name)\n\n\ninput_ids = tf.keras.layers.Input(shape=(seq_len,), name='input_ids', dtype='int32')\nmask = tf.keras.layers.Input(shape=(seq_len,), name='attention_mask', dtype='int32')\n\n\nembeddings = model(input_ids, attention_mask=mask)[0]\nembeddings = embeddings[:, 0, :]\n\nx = tf.keras.layers.Dense(512, activation='relu')(embeddings)\n\ny = tf.keras.layers.Dense(2, activation='softmax', name='outputs')(x)\n\nbert_model = tf.keras.Model(inputs=[input_ids, mask], outputs=y)\n\n\n\noptimizer = tf.keras.optimizers.Adam(learning_rate=1e-5)\nloss = tf.keras.losses.CategoricalCrossentropy()\nacc = tf.keras.metrics.BinaryAccuracy()\n\nbert_model.compile(optimizer=optimizer, loss=loss, metrics=[acc])\n\nhistory = bert_model.fit(\n    train_ds,\n    validation_data=val_ds,\n    epochs=8,\n    batch_size=30\n)","metadata":{"id":"cM6fa3vBJ23B","outputId":"7d92751e-5323-41f0-886a-d4f82c202e9b","execution":{"iopub.status.busy":"2023-10-05T09:16:35.418383Z","iopub.execute_input":"2023-10-05T09:16:35.418692Z"},"trusted":true},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading tf_model.h5:   0%|          | 0.00/501M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4224edd5915049d180762a3a33256e28"}},"metadata":{}},{"name":"stderr","text":"Some layers from the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment were not used when initializing TFRobertaModel: ['classifier']\n- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nAll the layers of TFRobertaModel were initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/8\n133/133 [==============================] - 216s 1s/step - loss: 0.4789 - binary_accuracy: 0.7729 - val_loss: 0.3458 - val_binary_accuracy: 0.8623\nEpoch 2/8\n133/133 [==============================] - 175s 1s/step - loss: 0.3844 - binary_accuracy: 0.8383 - val_loss: 0.3193 - val_binary_accuracy: 0.8724\nEpoch 3/8\n133/133 [==============================] - 175s 1s/step - loss: 0.3256 - binary_accuracy: 0.8660 - val_loss: 0.2911 - val_binary_accuracy: 0.8820\nEpoch 4/8\n133/133 [==============================] - 175s 1s/step - loss: 0.2979 - binary_accuracy: 0.8831 - val_loss: 0.2272 - val_binary_accuracy: 0.9167\nEpoch 5/8\n","output_type":"stream"}]},{"cell_type":"code","source":"bert_model.evaluate(val_ds)","metadata":{"id":"ehmxjYS4Q900","execution":{"iopub.status.busy":"2023-10-05T08:18:08.283023Z","iopub.execute_input":"2023-10-05T08:18:08.283391Z","iopub.status.idle":"2023-10-05T08:18:47.770671Z","shell.execute_reply.started":"2023-10-05T08:18:08.283364Z","shell.execute_reply":"2023-10-05T08:18:47.769488Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"143/143 [==============================] - 39s 275ms/step - loss: 0.0482 - binary_accuracy: 0.9799\n","output_type":"stream"},{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"[0.0481700673699379, 0.9798951148986816]"},"metadata":{}}]},{"cell_type":"code","source":"def prep_data(text):\n    tokens = tokenizer(\n        text, max_length=256, truncation=True,\n        padding='max_length',\n        add_special_tokens=True,\n        return_tensors='tf'\n    )\n    return {\n        'input_ids': tokens['input_ids'],\n        'attention_mask': tokens['attention_mask']\n    }\n\ntest['target'] = None\n\nfor i, row in test.iterrows():\n    tokens = prep_data(row['text'])\n    probs = bert_model.predict_on_batch(tokens)\n    pred = np.argmax(probs)\n    test.at[i, 'target'] = pred\n\ntest['target'] = test['target'].astype(int)","metadata":{"id":"MJ4vrs2NJ6jy","execution":{"iopub.status.busy":"2023-10-05T08:19:29.730748Z","iopub.execute_input":"2023-10-05T08:19:29.731123Z","iopub.status.idle":"2023-10-05T08:20:47.888172Z","shell.execute_reply.started":"2023-10-05T08:19:29.731089Z","shell.execute_reply":"2023-10-05T08:20:47.887201Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"test.head()","metadata":{"id":"5SMBxoWgRE5m","execution":{"iopub.status.busy":"2023-10-05T08:21:34.264085Z","iopub.execute_input":"2023-10-05T08:21:34.265038Z","iopub.status.idle":"2023-10-05T08:21:34.279982Z","shell.execute_reply.started":"2023-10-05T08:21:34.265004Z","shell.execute_reply":"2023-10-05T08:21:34.278870Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"   id keyword location                                               text  \\\n0   0     NaN      NaN                 just happened a terrible car crash   \n1   2     NaN      NaN  heard about earthquake is different cities, st...   \n2   3     NaN      NaN  there is a forest fire at spot pond, geese are...   \n3   9     NaN      NaN             apocalypse lighting. spokane wildfires   \n4  11     NaN      NaN      typhoon soudelor kills 28 in china and taiwan   \n\n   length  target  \n0      34       1  \n1      64       1  \n2      96       1  \n3      40       1  \n4      45       1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>keyword</th>\n      <th>location</th>\n      <th>text</th>\n      <th>length</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>just happened a terrible car crash</td>\n      <td>34</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>heard about earthquake is different cities, st...</td>\n      <td>64</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>there is a forest fire at spot pond, geese are...</td>\n      <td>96</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>apocalypse lighting. spokane wildfires</td>\n      <td>40</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>11</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>typhoon soudelor kills 28 in china and taiwan</td>\n      <td>45</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]}]}